{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "eiZrhk81mEZj"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import Sampler\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "l2VRK1zAIuTp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import scipy as sp\n",
        "import scipy.stats\n",
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "#FEATURE_DIM = 32\n",
        "#RELATION_DIM = 8\n",
        "CLASS_NUM = 5\n",
        "SAMPLE_NUM_PER_CLASS = 1   #5\n",
        "BATCH_NUM_PER_CLASS = 10   #10\n",
        "EPISODE = 1000\n",
        "TEST_EPISODE = 20\n",
        "LEARNING_RATE = 0.001\n",
        "GPU = 0\n",
        "HIDDEN_UNIT = 10\n",
        "PIXEL_SIM_METHOD = 'cosine'\n",
        "RESNET_OUT_H=4\n",
        "SEG=False# using segmentation result as dataset when SEG=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WmbECWLrmEZk"
      },
      "outputs": [],
      "source": [
        "def stanford_dog_folders(seg=True):\n",
        "    if (seg):\n",
        "      train_folder = \"data/seg/train\"\n",
        "      test_folder = \"data/seg/test\"                \n",
        "      val_folder = \"data/seg/val\"\n",
        "    else:\n",
        "      train_folder = \"data/sp/train\"\n",
        "      test_folder = \"data/sp/test\"                \n",
        "      val_folder = \"data/sp/val\"\n",
        "\n",
        "    metatrain_folders = [os.path.join(train_folder, label) \\\n",
        "                for label in os.listdir(train_folder) \\\n",
        "                if os.path.isdir(os.path.join(train_folder, label)) \\\n",
        "                ]\n",
        "    metatest_folders = [os.path.join(test_folder, label) \\\n",
        "                for label in os.listdir(test_folder) \\\n",
        "                if os.path.isdir(os.path.join(test_folder, label)) \\\n",
        "                ]\n",
        "    metaval_folders = [os.path.join(val_folder, label) \\\n",
        "                for label in os.listdir(val_folder) \\\n",
        "                if os.path.isdir(os.path.join(val_folder, label)) \\\n",
        "                ]\n",
        "    \n",
        "    #print(metaval_folders)\n",
        "\n",
        "    random.seed(1)\n",
        "    random.shuffle(metatrain_folders)\n",
        "    random.shuffle(metatest_folders)\n",
        "    random.shuffle(metaval_folders)\n",
        "    \n",
        "\n",
        "    return metatrain_folders,metatest_folders, metaval_folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def generate_csv(seg=False):\n",
        "    #return 3 list:train_folder,vla_folder,test_folder\n",
        "    #each list contains name of the specific class of the dog\n",
        "    #eg: train_folder=['data/sp/tain/n02085620-Chihuahua',...,...]\n",
        "    train_class_name_list=[]\n",
        "    val_class_name_list=[]\n",
        "    test_class_name_list=[]\n",
        "    train_img_name_list=[]\n",
        "    val_img_name_list=[]\n",
        "    test_img_name_list=[]\n",
        "    \n",
        "    if (seg):#if use segmentation data\n",
        "      train_folder = \"data/seg/train\"\n",
        "      test_folder = \"data/seg/test\"\n",
        "      val_folder = \"data/seg/val\"\n",
        "    else:\n",
        "      train_folder = \"data/sp/train\"\n",
        "      test_folder = \"data/sp/test\"                \n",
        "      val_folder = \"data/sp/val\"\n",
        "    \n",
        "    \n",
        "    for train_class_name in os.listdir(train_folder):\n",
        "      for train_img_name in os.listdir(os.path.join(train_folder,train_class_name)):\n",
        "        train_class_name_list.append(train_class_name)\n",
        "        train_img_name_list.append(os.path.join(os.path.join(train_folder,train_class_name),train_img_name))\n",
        "    df_train=pd.DataFrame({'category_name':'train','class_name':train_class_name_list,'img_name':train_img_name_list})\n",
        "      \n",
        "    for test_class_name in os.listdir(test_folder):\n",
        "      for test_img_name in os.listdir(os.path.join(test_folder,test_class_name)):\n",
        "        test_class_name_list.append(test_class_name)\n",
        "        test_img_name_list.append(os.path.join(os.path.join(test_folder,test_class_name),test_img_name))\n",
        "    df_test=pd.DataFrame({'category_name':'test','class_name':test_class_name_list,'img_name':test_img_name_list})\n",
        "      \n",
        "    for val_class_name in os.listdir(val_folder):\n",
        "      for val_img_name in os.listdir(os.path.join(val_folder,val_class_name)):\n",
        "        val_class_name_list.append(val_class_name)\n",
        "        val_img_name_list.append(os.path.join(os.path.join(val_folder,val_class_name),val_img_name))\n",
        "    df_val=pd.DataFrame({'category_name':'val','class_name':val_class_name_list,'img_name':val_img_name_list})\n",
        "    return (df_train,df_test,df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df_train,df_test,df_val)=generate_csv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_task(df,n_way,m_shot,t_query):\n",
        "    #generate task\n",
        "    #input: df:dataframe ie:df_train\n",
        "    #       n_way: how many class in each task\n",
        "    #       m_shot: use how many img in each class as support set\n",
        "    #       t_query: use how many img in each class to test the model\n",
        "    #output: df_support_set: dataframe of support_set,\n",
        "    #                        columns=['category_name','class_name','img_name'],\n",
        "    #                        len=(n_way*m_shot)\n",
        "    #\n",
        "    #        df_query_set: dataframe of query_set,\n",
        "    #                        columns=['category_name','class_name','img_name'],\n",
        "    #                        len=(n_way*t_query)\n",
        "    #\n",
        "    #        class_name_dict: dictionary from classname to class_number\n",
        "    df_support_set=pd.DataFrame(columns=['category_name','class_name','img_name'])\n",
        "    df_query_set=pd.DataFrame(columns=['category_name','class_name','img_name'])\n",
        "    class_name_dict={}\n",
        "    class_name_list=df.class_name.sample(n_way).values#randomly sample n_way different class\n",
        "    \n",
        "    for class_num in range(n_way):\n",
        "        class_name=class_name_list[class_num]\n",
        "        #print(class_name,class_num)\n",
        "        class_name_dict[class_name]=class_num\n",
        "        #print('mshot+tquery:',m_shot+t_query)\n",
        "        df_class_n=df[df['class_name']==class_name]\n",
        "        #print('class n len:',len(df_class_n))\n",
        "        df_class_n_random_pick=df_class_n.sample((m_shot+t_query))\n",
        "        #df_class_n=df[df['class_name']==class_name].sample((m_shot+t_query))\n",
        "        df_support_set=pd.concat([df_support_set,df_class_n_random_pick.head(m_shot)],axis=0,ignore_index=True)\n",
        "        df_query_set=pd.concat([df_query_set,df_class_n_random_pick.tail(t_query)],axis=0,ignore_index=True)\n",
        "    #df_support_set=df_support_set.reset_index()\n",
        "    #df_query_set=df_query_set.reset_index() \n",
        "    return (df_support_set,df_query_set,class_name_dict)\n",
        "        \n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, class_name_dict, transform = None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.class2index = class_name_dict\n",
        "        #print(self.class2index)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.df.iloc[index].img_name\n",
        "        label = self.class2index[self.df.iloc[index].class_name]\n",
        "        image = Image.open( filename)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_transform(normalizing=True):\n",
        "    if(normalizing):\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "        #resizing =  transforms.Resize(224, interpolation=2)\n",
        "        transform_method=transforms.Compose([transforms.ToTensor(),normalize])\n",
        "    else:\n",
        "        transform_method=transforms.ToTensor()\n",
        "    return transform_method\n",
        "\n",
        "transform_method=set_transform(normalizing=True)\n",
        "support_dataset=CustomDataset(df=df_support_set,class_name_dict=class_name_dict,transform=transform_method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "class PreTrainedResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    \n",
        "    self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "    #Set gradients to false\n",
        "    \n",
        "    for param in self.resnet18.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    num_feats = self.resnet18.fc.in_features\n",
        "    self.resnet18 = nn.Sequential(*(list(self.resnet18.children())[:-1]))\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #print('in defining network, input of Resnet is:',x.shape)\n",
        "    x = self.resnet18 (x)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.view(x.shape[0],32,4,4)\n",
        "    #print('in defining network, output of Resnet is:',x.shape)\n",
        "    return x\n",
        "\n",
        "class InnerproductSimilarity(nn.Module):\n",
        "    def __init__(self, CLASS_NUM = 5, shots = SAMPLE_NUM_PER_CLASS, metric='cosine',resnetoutsize=RESNET_OUT_H):\n",
        "        super().__init__()\n",
        "        self.n_way = CLASS_NUM\n",
        "        self.k_shot = shots\n",
        "        self.metric = metric\n",
        "        self.cs=nn.CosineSimilarity(dim=2)\n",
        "        \n",
        "        #self.cs=nn.PairwiseDistance()\n",
        "        \n",
        "        self.findmaxNotrain=nn.AvgPool3d(kernel_size=(shots,4,4),stride=(shots,4,4))\n",
        "        self.softmax=nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, support_features,query_features):\n",
        "        numOfSupport=support_features.size(dim=0)\n",
        "        numOfQuery=query_features.size(dim=0)\n",
        "        support_5d=support_features.unsqueeze(0)\n",
        "        support_5d_match=support_5d.repeat(numOfQuery,1,1,1,1)\n",
        "        query_5d=query_features.unsqueeze(1)\n",
        "        query_5d_match=query_5d.repeat(1,numOfSupport,1,1,1)#50,25,32,4,4\n",
        "        cos_similarity=self.cs(support_5d_match,query_5d_match)#50,25,4,4\n",
        "        score=self.findmaxNotrain(cos_similarity)#50,5每张test图片在每一类中的夹角均值\n",
        "        prob=self.softmax(score)\n",
        "        return score\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        n = m.weight.size(1)\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        m.bias.data = torch.ones(m.bias.data.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "feature_encoder = PreTrainedResNet()\n",
        "#feature_encoder.apply(weights_init)\n",
        "feature_encoder.cuda(0)\n",
        "\n",
        "\n",
        "pixelsimilarity_network = InnerproductSimilarity(CLASS_NUM = 5,shots = SAMPLE_NUM_PER_CLASS, metric='cosine',resnetoutsize=RESNET_OUT_H)\n",
        "pixelsimilarity_network.apply(weights_init)\n",
        "pixelsimilarity_network.cuda(0)\n",
        "\n",
        "feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=0.001)\n",
        "feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
        "#pixelsimilarity_network_optim = torch.optim.Adam(pixelsimilarity_network.parameters(),lr=0.001)\n",
        "#pixelsimilarity_network_scheduler = StepLR(pixelsimilarity_network_optim,step_size=100000,gamma=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_confidence_interval(data, confidence=0.95):\n",
        "    a = 1.0*np.array(data)\n",
        "    n = len(a)\n",
        "    m, se = np.mean(a), scipy.stats.sem(a)\n",
        "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
        "    return m,h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing...\n",
            "correct:47in50\n",
            "correct:48in50\n",
            "correct:44in50\n",
            "correct:47in50\n",
            "correct:48in50\n",
            "correct:46in50\n",
            "correct:48in50\n",
            "correct:46in50\n",
            "correct:31in50\n",
            "correct:49in50\n",
            "correct:44in50\n",
            "correct:45in50\n",
            "correct:50in50\n",
            "correct:45in50\n",
            "correct:45in50\n",
            "correct:31in50\n",
            "correct:38in50\n",
            "correct:48in50\n",
            "correct:32in50\n",
            "correct:35in50\n",
            "correct:22in50\n",
            "correct:49in50\n",
            "correct:38in50\n",
            "correct:38in50\n",
            "correct:40in50\n",
            "correct:37in50\n",
            "correct:31in50\n",
            "correct:45in50\n",
            "correct:46in50\n",
            "correct:46in50\n",
            "correct:50in50\n",
            "correct:46in50\n",
            "correct:44in50\n",
            "correct:47in50\n",
            "correct:44in50\n",
            "correct:40in50\n",
            "correct:31in50\n",
            "correct:46in50\n",
            "correct:40in50\n",
            "correct:49in50\n",
            "correct:40in50\n",
            "correct:50in50\n",
            "correct:44in50\n",
            "correct:48in50\n",
            "correct:41in50\n",
            "correct:45in50\n",
            "correct:23in50\n",
            "correct:47in50\n",
            "correct:37in50\n",
            "correct:48in50\n",
            "correct:31in50\n",
            "correct:32in50\n",
            "correct:50in50\n",
            "correct:42in50\n",
            "correct:47in50\n",
            "correct:50in50\n",
            "correct:46in50\n",
            "correct:48in50\n",
            "correct:37in50\n",
            "correct:48in50\n",
            "correct:46in50\n",
            "correct:49in50\n",
            "correct:47in50\n",
            "correct:47in50\n",
            "correct:38in50\n",
            "correct:46in50\n",
            "correct:48in50\n",
            "correct:34in50\n",
            "correct:43in50\n",
            "correct:36in50\n",
            "correct:39in50\n",
            "correct:35in50\n",
            "correct:45in50\n",
            "correct:50in50\n",
            "correct:48in50\n",
            "correct:43in50\n",
            "correct:46in50\n",
            "correct:46in50\n",
            "correct:49in50\n",
            "correct:48in50\n",
            "correct:48in50\n",
            "correct:32in50\n",
            "correct:46in50\n",
            "correct:47in50\n",
            "correct:48in50\n",
            "correct:48in50\n",
            "correct:47in50\n",
            "correct:50in50\n",
            "correct:48in50\n",
            "correct:38in50\n",
            "correct:28in50\n",
            "correct:50in50\n",
            "correct:39in50\n",
            "correct:44in50\n",
            "correct:32in50\n",
            "correct:47in50\n",
            "correct:37in50\n",
            "correct:47in50\n",
            "correct:34in50\n",
            "correct:48in50\n",
            "test accuracy: 0.8582 h: 0.02595907835264947\n"
          ]
        }
      ],
      "source": [
        "N_WAY=5\n",
        "M_SHOT=5\n",
        "T_QUERY=10\n",
        "\n",
        "feature_encoder = PreTrainedResNet()\n",
        "#feature_encoder.apply(weights_init)\n",
        "feature_encoder.cuda(0)\n",
        "\n",
        "\n",
        "pixelsimilarity_network = InnerproductSimilarity(CLASS_NUM = N_WAY,shots = M_SHOT, metric='cosine',resnetoutsize=RESNET_OUT_H)\n",
        "pixelsimilarity_network.apply(weights_init)\n",
        "pixelsimilarity_network.cuda(0)\n",
        "\n",
        "\n",
        "print(\"Testing...\")\n",
        "accuracies = []\n",
        "for i in range(100):\n",
        "  total_rewards = 0\n",
        "  df_support_set,df_query_set,class_name_dict=get_task(df=df_val,n_way=N_WAY,m_shot=M_SHOT,t_query=T_QUERY)\n",
        "  \n",
        "  transform_method=set_transform(normalizing=True)#preprocess of the data, usually are normalizing+totensor\n",
        "  \n",
        "  support_dataset=CustomDataset(df=df_support_set,class_name_dict=class_name_dict,transform=transform_method)\n",
        "  query_dataset=CustomDataset(df=df_query_set,class_name_dict=class_name_dict,transform=transform_method)\n",
        "  \n",
        "  \n",
        "  \n",
        "  support_dataloader=DataLoader(dataset=support_dataset,batch_size=N_WAY*M_SHOT,shuffle=False)\n",
        "  query_dataloader=DataLoader(dataset=query_dataset,batch_size=N_WAY*T_QUERY,shuffle=False)\n",
        "  \n",
        "\n",
        "  support_images,support_labels = support_dataloader.__iter__().next()\n",
        "  for test_images,test_labels in query_dataloader:\n",
        "    #print(test_labels)\n",
        "    support_features = feature_encoder(Variable(support_images).cuda(GPU)) # 5x64\n",
        "                \n",
        "    test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
        "\n",
        "               \n",
        "    \n",
        "    relations = pixelsimilarity_network(support_features,test_features)\n",
        "\n",
        "    _,predict_labels = torch.max(relations.data,dim=1)\n",
        "    \n",
        "\n",
        "    rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(N_WAY*T_QUERY)]\n",
        "    print('correct:{}in{}'.format(sum(rewards),len(rewards)))\n",
        "\n",
        "    total_rewards += np.sum(rewards)\n",
        "    #counter +=batch_size   #remove\n",
        "\n",
        "\n",
        "  accuracy = total_rewards/(1.0*N_WAY*T_QUERY)\n",
        "  #accuracy = total_rewards/1.0/counter\n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "test_accuracy,h = mean_confidence_interval(accuracies)\n",
        "\n",
        "print(\"test accuracy:\",test_accuracy,\"h:\",h)\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHDR5cFomEZl"
      },
      "source": [
        "超参数设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "feajSnE2mEZp"
      },
      "outputs": [],
      "source": [
        "class InnerproductSimilarity(nn.Module):\n",
        "    def __init__(self, CLASS_NUM = 5, shots = SAMPLE_NUM_PER_CLASS, metric='cosine',resnetoutsize=RESNET_OUT_H):\n",
        "        super().__init__()\n",
        "        self.n_way = CLASS_NUM\n",
        "        self.k_shot = shots\n",
        "        self.metric = metric\n",
        "        self.cs=nn.CosineSimilarity(dim=2)\n",
        "        \n",
        "        #self.cs=nn.PairwiseDistance()\n",
        "        \n",
        "        self.findmaxNotrain=nn.AvgPool3d(kernel_size=(shots,4,4),stride=(shots,4,4))\n",
        "        self.softmax=nn.Softmax(dim=1)\n",
        "    def forward(self, support_features,query_features):\n",
        "        numOfSupport=support_features.size(dim=0)\n",
        "        numOfQuery=query_features.size(dim=0)\n",
        "        #support_features(25,32,4,4)    query_features(1,32,4,4)\n",
        "        #print('before repeat: support',support_features.size(),'query:',query_features.size())\n",
        "        support_5d=support_features.unsqueeze(0)\n",
        "        support_5d_match=support_5d.repeat(numOfQuery,1,1,1,1)\n",
        "        query_5d=query_features.unsqueeze(1)\n",
        "        query_5d_match=query_5d.repeat(1,numOfSupport,1,1,1)#50,25,32,4,4\n",
        "        #print('we are in cosin similarity forward')\n",
        "        #print(support_5d_match.size(),query_5d_match.size())\n",
        "        cos_similarity=self.cs(support_5d_match,query_5d_match)#50,25,4,4\n",
        "        #print(cos_similarity.size())\n",
        "        '''angle=self.findmax(cos_similarity)\n",
        "        angle_reshape=angle.view((50,25))\n",
        "        hiden_score=self.fc1(angle_reshape)\n",
        "        score=self.fc2(hiden_score)'''\n",
        "        score=self.findmaxNotrain(cos_similarity)#50,5每张test图片在每一类中的夹角均值\n",
        "        prob=self.softmax(score)\n",
        "        return score\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_certentity=torch.softmax((relations-torch.mean(relations,dim=1,keepdim=True))/torch.std(relations,dim=1,keepdim=True),dim=1)\n",
        "_,b=torch.max(pixel_certentity,dim=1)\n",
        "f=b.cuda(0)!=test_labels.cuda(0)\n",
        "(pixel_certentity[f,predict_labels[f]]-pixel_certentity[f,test_labels[f]])*100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pixeltest.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f88223ccac6faceb13f29c80a3de01b7d01ef42a2fdac77949720970336c86df"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
